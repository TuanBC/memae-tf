{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MemAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuanBC/memae-tf/blob/master/MemAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA2xMGLxUAqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Các thuộc tính của Memory M\n",
        "\n",
        "class MemoryUnit(nn.Module):\n",
        "    def __init__(self, mem_dim, fea_dim, shrink_thres=0.0025):\n",
        "        super(MemoryUnit, self).__init__()\n",
        "        self.mem_dim = mem_dim # N\n",
        "        self.fea_dim = fea_dim # C\n",
        "        self.weight = Parameter(torch.Tensor(self.mem_dim, self.fea_dim))  # N x C\n",
        "        self.bias = None\n",
        "        self.shrink_thres= shrink_thres\n",
        "        # self.hard_sparse_shrink_opt = nn.Hardshrink(lambd=shrink_thres)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Hàm để khởi tạo weight và bias attention layer\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input: latent z\n",
        "        # Mem: bộ weight attention\n",
        "        \n",
        "        att_weight = F.linear(input, self.weight)  # Fea x Mem^T, (TxC) x (CxN) = TxN\n",
        "        att_weight = F.softmax(att_weight, dim=1)  # TxN\n",
        "        \n",
        "        # Dùng threshold để thay đổi att_weight\n",
        "\n",
        "        # ReLU based shrinkage, hard shrinkage for positive value\n",
        "        if(self.shrink_thres>0):\n",
        "\n",
        "            att_weight = hard_shrink_relu(att_weight, lambd=self.shrink_thres)\n",
        "            # att_weight = F.softshrink(att_weight, lambd=self.shrink_thres)\n",
        "            # normalize???\n",
        "            att_weight = F.normalize(att_weight, p=1, dim=1)\n",
        "            # att_weight = F.softmax(att_weight, dim=1)\n",
        "            # att_weight = self.hard_sparse_shrink_opt(att_weight)\n",
        "        \n",
        "        mem_trans = self.weight.permute(1, 0)  # Mem^T, MxC\n",
        "        output = F.linear(att_weight, mem_trans)  # AttWeight x Mem^T^T = AW x Mem, (TxM) x (MxC) = TxC\n",
        "        \n",
        "        return {'output': output, 'att': att_weight}  # output, att_weight\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'mem_dim={}, fea_dim={}'.format(\n",
        "            self.mem_dim, self.fea_dim is not None\n",
        "        )\n",
        "\n",
        "\n",
        "# NxCxHxW -> (NxHxW)xC -> addressing Mem, (NxHxW)xC -> NxCxHxW\n",
        "class MemModule(nn.Module):\n",
        "    def __init__(self, mem_dim, fea_dim, shrink_thres=0.0025, device='cuda'):\n",
        "        super(MemModule, self).__init__()\n",
        "        self.mem_dim = mem_dim\n",
        "        self.fea_dim = fea_dim\n",
        "        self.shrink_thres = shrink_thres\n",
        "        self.memory = MemoryUnit(self.mem_dim, self.fea_dim, self.shrink_thres)\n",
        "\n",
        "    def forward(self, input):\n",
        "        s = input.data.shape\n",
        "        l = len(s)\n",
        "\n",
        "        # Số chiều input z (latent)\n",
        "\n",
        "        if l == 3:\n",
        "            x = input.permute(0, 2, 1)\n",
        "        elif l == 4:\n",
        "            x = input.permute(0, 2, 3, 1)\n",
        "        elif l == 5:\n",
        "            x = input.permute(0, 2, 3, 4, 1)\n",
        "        else:\n",
        "            x = []\n",
        "            print('wrong feature map size')\n",
        "        x = x.contiguous()\n",
        "        x = x.view(-1, s[1])\n",
        "        #\n",
        "        y_and = self.memory(x)\n",
        "        \n",
        "        # y: output\n",
        "        # att: attention weight w\n",
        "\n",
        "        y = y_and['output']\n",
        "        att = y_and['att']\n",
        "\n",
        "        if l == 3:\n",
        "            y = y.view(s[0], s[2], s[1])\n",
        "            y = y.permute(0, 2, 1)\n",
        "            att = att.view(s[0], s[2], self.mem_dim)\n",
        "            att = att.permute(0, 2, 1)\n",
        "        elif l == 4:\n",
        "            y = y.view(s[0], s[2], s[3], s[1])\n",
        "            y = y.permute(0, 3, 1, 2)\n",
        "            att = att.view(s[0], s[2], s[3], self.mem_dim)\n",
        "            att = att.permute(0, 3, 1, 2)\n",
        "        elif l == 5:\n",
        "            y = y.view(s[0], s[2], s[3], s[4], s[1])\n",
        "            y = y.permute(0, 4, 1, 2, 3)\n",
        "            att = att.view(s[0], s[2], s[3], s[4], self.mem_dim)\n",
        "            att = att.permute(0, 4, 1, 2, 3)\n",
        "        else:\n",
        "            y = x\n",
        "            att = att\n",
        "            print('wrong feature map size')\n",
        "        return {'output': y, 'att': att}\n",
        "\n",
        "# relu based hard shrinkage function, only works for positive values\n",
        "\n",
        "def hard_shrink_relu(input, lambd=0, epsilon=1e-12):\n",
        "    output = (F.relu(input-lambd) * input) / (torch.abs(input - lambd) + epsilon)\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeRuSab72DaT",
        "colab_type": "code",
        "outputId": "9bc89bea-c9ab-4a90-d529-6338dbaf1a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFqhpPE4ksj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import softmax, relu\n",
        "from tensorflow.keras.initializers import RandomUniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2p0B8822BXg",
        "colab_type": "code",
        "outputId": "7f45d5b0-2106-48c4-a4d3-8ba948bfdcee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = tf.constant([[[1.0, 2.0]]])\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[[1. 2.]]], shape=(1, 1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahiz_5hy3tft",
        "colab_type": "code",
        "outputId": "2d2a23b8-0d0c-4c30-c59a-d1f7d5bc4adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "d = tf.constant([[1.0, 2.0], [30.0, -4.0], [1,1]])\n",
        "print(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.  2.]\n",
            " [30. -4.]\n",
            " [ 1.  1.]], shape=(3, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsLeowkGgAyK",
        "colab_type": "code",
        "outputId": "ddded5ce-0b0a-46c7-86e9-50b2f3ef45b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "tf.linalg.normalize(d, ord=1, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=5, shape=(3, 2), dtype=float32, numpy=\n",
              " array([[ 0.33333334,  0.6666667 ],\n",
              "        [ 0.88235295, -0.11764706],\n",
              "        [ 0.5       ,  0.5       ]], dtype=float32)>,\n",
              " <tf.Tensor: id=4, shape=(3, 1), dtype=float32, numpy=\n",
              " array([[ 3.],\n",
              "        [34.],\n",
              "        [ 2.]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TVhFEUI27V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_swap_last_2_axis(x):\n",
        "    if tf.rank(x)<=2:\n",
        "        return tf.transpose(x)\n",
        "    else:\n",
        "        # check again in case rank>2\n",
        "        return tf.transpose(x, [i for i in range(tf.shape(x).shape[0]-2)] + [tf.shape(x).shape[0]-2, tf.shape(x).shape[0]-1])\n",
        "    \n",
        "# tf_swap_last_2_axis_test(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5b35olWC1-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cosine_distances(a, b):\n",
        "    # a: Input, shape = (batch * n_a * fea_dim) \n",
        "    # b: Memory, shape = (n_b * fea_dim)\n",
        "    \n",
        "    # output: shape = (batch * n_a * n_b)\n",
        "\n",
        "    a_normalized, _ = tf.linalg.normalize(a, ord=1, axis=-1)\n",
        "    b_normalized, _ = tf.linalg.normalize(b, ord=1, axis=-1)\n",
        "    \n",
        "    # b_normalized_transposed = tf_swap_last_2_axis(b_normalized)\n",
        "    b_normalized_transposed = tf.transpose(b_normalized)\n",
        "    \n",
        "    distance = tf.matmul(a_normalized, b_normalized_transposed)\n",
        "\n",
        "    return distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R065R3BBOxPN",
        "colab_type": "code",
        "outputId": "f0c71935-7fe7-4a10-c9cd-77cf828853e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.rank(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=6, shape=(), dtype=int32, numpy=2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwPcuYxKPaG4",
        "colab_type": "code",
        "outputId": "8939fc01-eb30-4d4e-8d0d-82fe33566185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(compute_cosine_distances(c, d))\n",
        "print(compute_cosine_distances(c, tf.squeeze(c, 0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[[0.5555556  0.21568629 0.5       ]]], shape=(1, 1, 3), dtype=float32)\n",
            "tf.Tensor([[[0.5555556]]], shape=(1, 1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxfU-D4r5hw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next step: add regularizer\n",
        "\n",
        "class MemoryUnit(Layer):\n",
        "    def __init__(self, mem_dim, shrink_thres=0.0025):\n",
        "        # C: dimension of vector z\n",
        "        # M: size of the memory\n",
        "        super(MemoryUnit, self).__init__()\n",
        "        self.mem_dim = mem_dim\n",
        "        self.kernel_regularizer = None\n",
        "        self.shrink_thres= shrink_thres\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.std = 8\n",
        "        \n",
        "        # M x C\n",
        "        self.weight = self.add_weight(shape=(self.mem_dim, input_shape[-1]),\n",
        "                                      initializer=RandomUniform(-self.std, self.std, seed=2803),\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # att_weight = F.linear(inputs, self.weight)  # Fea x Mem^T, (TxC) x (CxM) = TxM\n",
        "        # att_weight = F.softmax(att_weight, dim=1)  # TxM\n",
        "\n",
        "        att_weight = compute_cosine_distances(inputs, self.weight) # Fea x Mem^T, (batchxTxC) x (CxM) = TxM\n",
        "        # att_weight = tf.matmul(inputs, tf.transpose(self.weight))\n",
        "        att_weight = softmax(att_weight) # TxM\n",
        "\n",
        "        if(self.shrink_thres>0):\n",
        "            att_weight = relu(att_weight, threshold=self.shrink_thres)\n",
        "\n",
        "            # normalize by p=1 (L1 normalization)\n",
        "            att_weight, _ = tf.linalg.normalize(att_weight, ord=1, axis=1)\n",
        "        output = tf.matmul(att_weight, self.weight)\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yk9XQu3f0oE",
        "colab_type": "code",
        "outputId": "715e68bb-550e-445c-c772-2aca7ea218d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(train_images, train_label), (test_images, test_label) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# Normalizing the images to the range of [0., 1.]\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "\n",
        "# Binarization\n",
        "train_images[train_images >= .5] = 1.\n",
        "train_images[train_images < .5] = 0.\n",
        "test_images[test_images >= .5] = 1.\n",
        "test_images[test_images < .5] = 0.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GNj74RXufdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_class = 9\n",
        "\n",
        "train_normal_images = train_images[train_label==normal_class]\n",
        "train_normal_label = train_label[train_label==normal_class]\n",
        "\n",
        "train_anomaly_images = train_images[train_label!=normal_class]\n",
        "train_anomaly_label = train_label[train_label!=normal_class]\n",
        "\n",
        "test_normal_images = test_images[test_label==normal_class]\n",
        "test_normal_label = test_label[test_label==normal_class]\n",
        "\n",
        "test_anomaly_images = test_images[test_label!=normal_class]\n",
        "test_anomaly_label = test_label[test_label!=normal_class]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmYDzhD2f5Cf",
        "colab_type": "code",
        "outputId": "ae0f1c95-8718-4570-83b9-ef5665000401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbsIxLFkGIXm",
        "colab_type": "code",
        "outputId": "7fe1fdd3-5009-4771-a37f-d7aed9708d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "x_input = Input(shape=[28,28,1])\n",
        "\n",
        "# x = Conv2D(8, 3, 1, 'same')(x_input)\n",
        "\n",
        "x = Flatten()(x_input)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(64, activation='relu', name='latent')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(784, activation='relu')(x)\n",
        "\n",
        "x = Reshape((28,28,1))(x)\n",
        "\n",
        "\n",
        "model = Model(x_input, x)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "latent (Dense)               (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 784)               201488    \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 435,536\n",
            "Trainable params: 435,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSj8noN2GQOV",
        "colab_type": "code",
        "outputId": "587e7f10-e3ac-4007-d28a-e7cf4e5b008d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit(train_normal_images, train_normal_images, batch_size=1024, epochs=100, validation_split=0.1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5354 samples, validate on 595 samples\n",
            "Epoch 1/100\n",
            "5354/5354 - 1s - loss: 0.1037 - val_loss: 0.0779\n",
            "Epoch 2/100\n",
            "5354/5354 - 0s - loss: 0.0740 - val_loss: 0.0649\n",
            "Epoch 3/100\n",
            "5354/5354 - 0s - loss: 0.0641 - val_loss: 0.0579\n",
            "Epoch 4/100\n",
            "5354/5354 - 0s - loss: 0.0574 - val_loss: 0.0526\n",
            "Epoch 5/100\n",
            "5354/5354 - 0s - loss: 0.0522 - val_loss: 0.0480\n",
            "Epoch 6/100\n",
            "5354/5354 - 0s - loss: 0.0477 - val_loss: 0.0442\n",
            "Epoch 7/100\n",
            "5354/5354 - 0s - loss: 0.0442 - val_loss: 0.0411\n",
            "Epoch 8/100\n",
            "5354/5354 - 0s - loss: 0.0410 - val_loss: 0.0382\n",
            "Epoch 9/100\n",
            "5354/5354 - 0s - loss: 0.0380 - val_loss: 0.0354\n",
            "Epoch 10/100\n",
            "5354/5354 - 0s - loss: 0.0353 - val_loss: 0.0328\n",
            "Epoch 11/100\n",
            "5354/5354 - 0s - loss: 0.0329 - val_loss: 0.0308\n",
            "Epoch 12/100\n",
            "5354/5354 - 0s - loss: 0.0310 - val_loss: 0.0292\n",
            "Epoch 13/100\n",
            "5354/5354 - 0s - loss: 0.0293 - val_loss: 0.0277\n",
            "Epoch 14/100\n",
            "5354/5354 - 0s - loss: 0.0278 - val_loss: 0.0265\n",
            "Epoch 15/100\n",
            "5354/5354 - 0s - loss: 0.0267 - val_loss: 0.0255\n",
            "Epoch 16/100\n",
            "5354/5354 - 0s - loss: 0.0257 - val_loss: 0.0247\n",
            "Epoch 17/100\n",
            "5354/5354 - 0s - loss: 0.0249 - val_loss: 0.0240\n",
            "Epoch 18/100\n",
            "5354/5354 - 0s - loss: 0.0241 - val_loss: 0.0233\n",
            "Epoch 19/100\n",
            "5354/5354 - 0s - loss: 0.0233 - val_loss: 0.0228\n",
            "Epoch 20/100\n",
            "5354/5354 - 0s - loss: 0.0227 - val_loss: 0.0222\n",
            "Epoch 21/100\n",
            "5354/5354 - 0s - loss: 0.0222 - val_loss: 0.0218\n",
            "Epoch 22/100\n",
            "5354/5354 - 0s - loss: 0.0218 - val_loss: 0.0214\n",
            "Epoch 23/100\n",
            "5354/5354 - 0s - loss: 0.0213 - val_loss: 0.0210\n",
            "Epoch 24/100\n",
            "5354/5354 - 0s - loss: 0.0210 - val_loss: 0.0207\n",
            "Epoch 25/100\n",
            "5354/5354 - 0s - loss: 0.0207 - val_loss: 0.0204\n",
            "Epoch 26/100\n",
            "5354/5354 - 0s - loss: 0.0203 - val_loss: 0.0201\n",
            "Epoch 27/100\n",
            "5354/5354 - 0s - loss: 0.0200 - val_loss: 0.0198\n",
            "Epoch 28/100\n",
            "5354/5354 - 0s - loss: 0.0197 - val_loss: 0.0197\n",
            "Epoch 29/100\n",
            "5354/5354 - 0s - loss: 0.0194 - val_loss: 0.0193\n",
            "Epoch 30/100\n",
            "5354/5354 - 0s - loss: 0.0193 - val_loss: 0.0193\n",
            "Epoch 31/100\n",
            "5354/5354 - 0s - loss: 0.0190 - val_loss: 0.0190\n",
            "Epoch 32/100\n",
            "5354/5354 - 0s - loss: 0.0188 - val_loss: 0.0188\n",
            "Epoch 33/100\n",
            "5354/5354 - 0s - loss: 0.0186 - val_loss: 0.0187\n",
            "Epoch 34/100\n",
            "5354/5354 - 0s - loss: 0.0184 - val_loss: 0.0186\n",
            "Epoch 35/100\n",
            "5354/5354 - 0s - loss: 0.0183 - val_loss: 0.0184\n",
            "Epoch 36/100\n",
            "5354/5354 - 0s - loss: 0.0181 - val_loss: 0.0182\n",
            "Epoch 37/100\n",
            "5354/5354 - 0s - loss: 0.0179 - val_loss: 0.0181\n",
            "Epoch 38/100\n",
            "5354/5354 - 0s - loss: 0.0178 - val_loss: 0.0179\n",
            "Epoch 39/100\n",
            "5354/5354 - 0s - loss: 0.0176 - val_loss: 0.0180\n",
            "Epoch 40/100\n",
            "5354/5354 - 0s - loss: 0.0175 - val_loss: 0.0178\n",
            "Epoch 41/100\n",
            "5354/5354 - 0s - loss: 0.0173 - val_loss: 0.0176\n",
            "Epoch 42/100\n",
            "5354/5354 - 0s - loss: 0.0172 - val_loss: 0.0175\n",
            "Epoch 43/100\n",
            "5354/5354 - 0s - loss: 0.0171 - val_loss: 0.0174\n",
            "Epoch 44/100\n",
            "5354/5354 - 0s - loss: 0.0170 - val_loss: 0.0173\n",
            "Epoch 45/100\n",
            "5354/5354 - 0s - loss: 0.0169 - val_loss: 0.0172\n",
            "Epoch 46/100\n",
            "5354/5354 - 0s - loss: 0.0168 - val_loss: 0.0171\n",
            "Epoch 47/100\n",
            "5354/5354 - 0s - loss: 0.0167 - val_loss: 0.0171\n",
            "Epoch 48/100\n",
            "5354/5354 - 0s - loss: 0.0166 - val_loss: 0.0170\n",
            "Epoch 49/100\n",
            "5354/5354 - 0s - loss: 0.0165 - val_loss: 0.0169\n",
            "Epoch 50/100\n",
            "5354/5354 - 0s - loss: 0.0164 - val_loss: 0.0168\n",
            "Epoch 51/100\n",
            "5354/5354 - 0s - loss: 0.0163 - val_loss: 0.0167\n",
            "Epoch 52/100\n",
            "5354/5354 - 0s - loss: 0.0162 - val_loss: 0.0167\n",
            "Epoch 53/100\n",
            "5354/5354 - 0s - loss: 0.0162 - val_loss: 0.0167\n",
            "Epoch 54/100\n",
            "5354/5354 - 0s - loss: 0.0162 - val_loss: 0.0166\n",
            "Epoch 55/100\n",
            "5354/5354 - 0s - loss: 0.0161 - val_loss: 0.0166\n",
            "Epoch 56/100\n",
            "5354/5354 - 0s - loss: 0.0160 - val_loss: 0.0165\n",
            "Epoch 57/100\n",
            "5354/5354 - 0s - loss: 0.0159 - val_loss: 0.0164\n",
            "Epoch 58/100\n",
            "5354/5354 - 0s - loss: 0.0158 - val_loss: 0.0163\n",
            "Epoch 59/100\n",
            "5354/5354 - 0s - loss: 0.0157 - val_loss: 0.0163\n",
            "Epoch 60/100\n",
            "5354/5354 - 0s - loss: 0.0157 - val_loss: 0.0162\n",
            "Epoch 61/100\n",
            "5354/5354 - 0s - loss: 0.0156 - val_loss: 0.0162\n",
            "Epoch 62/100\n",
            "5354/5354 - 0s - loss: 0.0155 - val_loss: 0.0161\n",
            "Epoch 63/100\n",
            "5354/5354 - 0s - loss: 0.0155 - val_loss: 0.0160\n",
            "Epoch 64/100\n",
            "5354/5354 - 0s - loss: 0.0154 - val_loss: 0.0160\n",
            "Epoch 65/100\n",
            "5354/5354 - 0s - loss: 0.0154 - val_loss: 0.0160\n",
            "Epoch 66/100\n",
            "5354/5354 - 0s - loss: 0.0153 - val_loss: 0.0159\n",
            "Epoch 67/100\n",
            "5354/5354 - 0s - loss: 0.0153 - val_loss: 0.0159\n",
            "Epoch 68/100\n",
            "5354/5354 - 0s - loss: 0.0152 - val_loss: 0.0158\n",
            "Epoch 69/100\n",
            "5354/5354 - 0s - loss: 0.0152 - val_loss: 0.0158\n",
            "Epoch 70/100\n",
            "5354/5354 - 0s - loss: 0.0151 - val_loss: 0.0158\n",
            "Epoch 71/100\n",
            "5354/5354 - 0s - loss: 0.0150 - val_loss: 0.0157\n",
            "Epoch 72/100\n",
            "5354/5354 - 0s - loss: 0.0150 - val_loss: 0.0157\n",
            "Epoch 73/100\n",
            "5354/5354 - 0s - loss: 0.0149 - val_loss: 0.0156\n",
            "Epoch 74/100\n",
            "5354/5354 - 0s - loss: 0.0149 - val_loss: 0.0156\n",
            "Epoch 75/100\n",
            "5354/5354 - 0s - loss: 0.0148 - val_loss: 0.0156\n",
            "Epoch 76/100\n",
            "5354/5354 - 0s - loss: 0.0148 - val_loss: 0.0156\n",
            "Epoch 77/100\n",
            "5354/5354 - 0s - loss: 0.0147 - val_loss: 0.0155\n",
            "Epoch 78/100\n",
            "5354/5354 - 0s - loss: 0.0147 - val_loss: 0.0155\n",
            "Epoch 79/100\n",
            "5354/5354 - 0s - loss: 0.0147 - val_loss: 0.0155\n",
            "Epoch 80/100\n",
            "5354/5354 - 0s - loss: 0.0146 - val_loss: 0.0155\n",
            "Epoch 81/100\n",
            "5354/5354 - 0s - loss: 0.0146 - val_loss: 0.0154\n",
            "Epoch 82/100\n",
            "5354/5354 - 0s - loss: 0.0146 - val_loss: 0.0154\n",
            "Epoch 83/100\n",
            "5354/5354 - 0s - loss: 0.0146 - val_loss: 0.0154\n",
            "Epoch 84/100\n",
            "5354/5354 - 0s - loss: 0.0146 - val_loss: 0.0153\n",
            "Epoch 85/100\n",
            "5354/5354 - 0s - loss: 0.0145 - val_loss: 0.0153\n",
            "Epoch 86/100\n",
            "5354/5354 - 0s - loss: 0.0144 - val_loss: 0.0153\n",
            "Epoch 87/100\n",
            "5354/5354 - 0s - loss: 0.0144 - val_loss: 0.0152\n",
            "Epoch 88/100\n",
            "5354/5354 - 0s - loss: 0.0143 - val_loss: 0.0152\n",
            "Epoch 89/100\n",
            "5354/5354 - 0s - loss: 0.0143 - val_loss: 0.0152\n",
            "Epoch 90/100\n",
            "5354/5354 - 0s - loss: 0.0143 - val_loss: 0.0151\n",
            "Epoch 91/100\n",
            "5354/5354 - 0s - loss: 0.0142 - val_loss: 0.0151\n",
            "Epoch 92/100\n",
            "5354/5354 - 0s - loss: 0.0142 - val_loss: 0.0151\n",
            "Epoch 93/100\n",
            "5354/5354 - 0s - loss: 0.0142 - val_loss: 0.0150\n",
            "Epoch 94/100\n",
            "5354/5354 - 0s - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 95/100\n",
            "5354/5354 - 0s - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 96/100\n",
            "5354/5354 - 0s - loss: 0.0141 - val_loss: 0.0151\n",
            "Epoch 97/100\n",
            "5354/5354 - 0s - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 98/100\n",
            "5354/5354 - 0s - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 99/100\n",
            "5354/5354 - 0s - loss: 0.0140 - val_loss: 0.0150\n",
            "Epoch 100/100\n",
            "5354/5354 - 0s - loss: 0.0140 - val_loss: 0.0150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ffce054a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gELuV2PvVkO",
        "colab_type": "code",
        "outputId": "e006ceab-3321-45bf-d5d1-2e61cd8eda54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(train_anomaly_images, train_anomaly_images, batch_size=1024, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54051/1 - 0s - loss: 0.0478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0456561155160148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGCVjt6fHXDF",
        "colab_type": "code",
        "outputId": "cbd86ef7-3d95-420c-f8e6-9b986b44cc58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "x_input = Input(shape=[28,28,1])\n",
        "\n",
        "# x = Conv2D(8, 3, 1, 'same')(x_input)\n",
        "\n",
        "x = Flatten()(x_input)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "x = MemoryUnit(100)(x)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(784, activation='relu')(x)\n",
        "\n",
        "x = Reshape((28,28,1))(x)\n",
        "\n",
        "\n",
        "model_2 = Model(x_input, x)\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "memory_unit_4 (MemoryUnit)   (None, 64)                6400      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 784)               201488    \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 441,936\n",
            "Trainable params: 441,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNgnwTiUOUqP",
        "colab_type": "code",
        "outputId": "39fb7aa8-f21c-454f-9086-6d3108925c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_2.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_2.fit(train_normal_images, train_normal_images, batch_size=1024, epochs=100, validation_split=0.1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5354 samples, validate on 595 samples\n",
            "Epoch 1/100\n",
            "5354/5354 - 1s - loss: 0.1108 - val_loss: 0.0961\n",
            "Epoch 2/100\n",
            "5354/5354 - 0s - loss: 0.0962 - val_loss: 0.0912\n",
            "Epoch 3/100\n",
            "5354/5354 - 0s - loss: 0.0930 - val_loss: 0.0893\n",
            "Epoch 4/100\n",
            "5354/5354 - 0s - loss: 0.0914 - val_loss: 0.0883\n",
            "Epoch 5/100\n",
            "5354/5354 - 0s - loss: 0.0904 - val_loss: 0.0872\n",
            "Epoch 6/100\n",
            "5354/5354 - 0s - loss: 0.0893 - val_loss: 0.0862\n",
            "Epoch 7/100\n",
            "5354/5354 - 0s - loss: 0.0886 - val_loss: 0.0857\n",
            "Epoch 8/100\n",
            "5354/5354 - 0s - loss: 0.0883 - val_loss: 0.0855\n",
            "Epoch 9/100\n",
            "5354/5354 - 0s - loss: 0.0882 - val_loss: 0.0854\n",
            "Epoch 10/100\n",
            "5354/5354 - 0s - loss: 0.1030 - val_loss: 0.1191\n",
            "Epoch 11/100\n",
            "5354/5354 - 0s - loss: 0.1223 - val_loss: 0.1181\n",
            "Epoch 12/100\n",
            "5354/5354 - 0s - loss: 0.1211 - val_loss: 0.1169\n",
            "Epoch 13/100\n",
            "5354/5354 - 0s - loss: 0.1199 - val_loss: 0.1157\n",
            "Epoch 14/100\n",
            "5354/5354 - 0s - loss: 0.1187 - val_loss: 0.1145\n",
            "Epoch 15/100\n",
            "5354/5354 - 0s - loss: 0.1175 - val_loss: 0.1134\n",
            "Epoch 16/100\n",
            "5354/5354 - 0s - loss: 0.1164 - val_loss: 0.1124\n",
            "Epoch 17/100\n",
            "5354/5354 - 0s - loss: 0.1154 - val_loss: 0.1114\n",
            "Epoch 18/100\n",
            "5354/5354 - 0s - loss: 0.1144 - val_loss: 0.1105\n",
            "Epoch 19/100\n",
            "5354/5354 - 0s - loss: 0.1135 - val_loss: 0.1096\n",
            "Epoch 20/100\n",
            "5354/5354 - 0s - loss: 0.1126 - val_loss: 0.1088\n",
            "Epoch 21/100\n",
            "5354/5354 - 0s - loss: 0.1118 - val_loss: 0.1080\n",
            "Epoch 22/100\n",
            "5354/5354 - 0s - loss: 0.1110 - val_loss: 0.1073\n",
            "Epoch 23/100\n",
            "5354/5354 - 0s - loss: 0.1103 - val_loss: 0.1066\n",
            "Epoch 24/100\n",
            "5354/5354 - 0s - loss: 0.1096 - val_loss: 0.1059\n",
            "Epoch 25/100\n",
            "5354/5354 - 0s - loss: 0.1089 - val_loss: 0.1053\n",
            "Epoch 26/100\n",
            "5354/5354 - 0s - loss: 0.1083 - val_loss: 0.1047\n",
            "Epoch 27/100\n",
            "5354/5354 - 0s - loss: 0.1077 - val_loss: 0.1041\n",
            "Epoch 28/100\n",
            "5354/5354 - 0s - loss: 0.1071 - val_loss: 0.1035\n",
            "Epoch 29/100\n",
            "5354/5354 - 0s - loss: 0.1065 - val_loss: 0.1030\n",
            "Epoch 30/100\n",
            "5354/5354 - 0s - loss: 0.1060 - val_loss: 0.1024\n",
            "Epoch 31/100\n",
            "5354/5354 - 0s - loss: 0.1054 - val_loss: 0.1019\n",
            "Epoch 32/100\n",
            "5354/5354 - 0s - loss: 0.1049 - val_loss: 0.1014\n",
            "Epoch 33/100\n",
            "5354/5354 - 0s - loss: 0.1044 - val_loss: 0.1010\n",
            "Epoch 34/100\n",
            "5354/5354 - 0s - loss: 0.1039 - val_loss: 0.1005\n",
            "Epoch 35/100\n",
            "5354/5354 - 0s - loss: 0.1035 - val_loss: 0.1001\n",
            "Epoch 36/100\n",
            "5354/5354 - 0s - loss: 0.1030 - val_loss: 0.0996\n",
            "Epoch 37/100\n",
            "5354/5354 - 0s - loss: 0.1026 - val_loss: 0.0992\n",
            "Epoch 38/100\n",
            "5354/5354 - 0s - loss: 0.1022 - val_loss: 0.0988\n",
            "Epoch 39/100\n",
            "5354/5354 - 0s - loss: 0.1018 - val_loss: 0.0984\n",
            "Epoch 40/100\n",
            "5354/5354 - 0s - loss: 0.1014 - val_loss: 0.0981\n",
            "Epoch 41/100\n",
            "5354/5354 - 0s - loss: 0.1010 - val_loss: 0.0977\n",
            "Epoch 42/100\n",
            "5354/5354 - 0s - loss: 0.1007 - val_loss: 0.0973\n",
            "Epoch 43/100\n",
            "5354/5354 - 0s - loss: 0.1003 - val_loss: 0.0970\n",
            "Epoch 44/100\n",
            "5354/5354 - 0s - loss: 0.1000 - val_loss: 0.0967\n",
            "Epoch 45/100\n",
            "5354/5354 - 0s - loss: 0.0996 - val_loss: 0.0963\n",
            "Epoch 46/100\n",
            "5354/5354 - 0s - loss: 0.0993 - val_loss: 0.0960\n",
            "Epoch 47/100\n",
            "5354/5354 - 0s - loss: 0.0990 - val_loss: 0.0957\n",
            "Epoch 48/100\n",
            "5354/5354 - 0s - loss: 0.0987 - val_loss: 0.0954\n",
            "Epoch 49/100\n",
            "5354/5354 - 0s - loss: 0.0984 - val_loss: 0.0952\n",
            "Epoch 50/100\n",
            "5354/5354 - 0s - loss: 0.0981 - val_loss: 0.0949\n",
            "Epoch 51/100\n",
            "5354/5354 - 0s - loss: 0.0978 - val_loss: 0.0946\n",
            "Epoch 52/100\n",
            "5354/5354 - 0s - loss: 0.0975 - val_loss: 0.0943\n",
            "Epoch 53/100\n",
            "5354/5354 - 0s - loss: 0.0973 - val_loss: 0.0941\n",
            "Epoch 54/100\n",
            "5354/5354 - 0s - loss: 0.0970 - val_loss: 0.0939\n",
            "Epoch 55/100\n",
            "5354/5354 - 0s - loss: 0.0968 - val_loss: 0.0936\n",
            "Epoch 56/100\n",
            "5354/5354 - 0s - loss: 0.0965 - val_loss: 0.0934\n",
            "Epoch 57/100\n",
            "5354/5354 - 0s - loss: 0.0963 - val_loss: 0.0932\n",
            "Epoch 58/100\n",
            "5354/5354 - 0s - loss: 0.0961 - val_loss: 0.0929\n",
            "Epoch 59/100\n",
            "5354/5354 - 0s - loss: 0.0959 - val_loss: 0.0927\n",
            "Epoch 60/100\n",
            "5354/5354 - 0s - loss: 0.0957 - val_loss: 0.0925\n",
            "Epoch 61/100\n",
            "5354/5354 - 0s - loss: 0.0955 - val_loss: 0.0923\n",
            "Epoch 62/100\n",
            "5354/5354 - 0s - loss: 0.0953 - val_loss: 0.0921\n",
            "Epoch 63/100\n",
            "5354/5354 - 0s - loss: 0.0951 - val_loss: 0.0920\n",
            "Epoch 64/100\n",
            "5354/5354 - 0s - loss: 0.0949 - val_loss: 0.0918\n",
            "Epoch 65/100\n",
            "5354/5354 - 0s - loss: 0.0947 - val_loss: 0.0916\n",
            "Epoch 66/100\n",
            "5354/5354 - 0s - loss: 0.0945 - val_loss: 0.0914\n",
            "Epoch 67/100\n",
            "5354/5354 - 0s - loss: 0.0943 - val_loss: 0.0913\n",
            "Epoch 68/100\n",
            "5354/5354 - 0s - loss: 0.0942 - val_loss: 0.0911\n",
            "Epoch 69/100\n",
            "5354/5354 - 0s - loss: 0.0940 - val_loss: 0.0909\n",
            "Epoch 70/100\n",
            "5354/5354 - 0s - loss: 0.0939 - val_loss: 0.0908\n",
            "Epoch 71/100\n",
            "5354/5354 - 0s - loss: 0.0937 - val_loss: 0.0906\n",
            "Epoch 72/100\n",
            "5354/5354 - 0s - loss: 0.0936 - val_loss: 0.0905\n",
            "Epoch 73/100\n",
            "5354/5354 - 0s - loss: 0.0934 - val_loss: 0.0904\n",
            "Epoch 74/100\n",
            "5354/5354 - 0s - loss: 0.0933 - val_loss: 0.0902\n",
            "Epoch 75/100\n",
            "5354/5354 - 0s - loss: 0.0931 - val_loss: 0.0901\n",
            "Epoch 76/100\n",
            "5354/5354 - 0s - loss: 0.0930 - val_loss: 0.0900\n",
            "Epoch 77/100\n",
            "5354/5354 - 0s - loss: 0.0929 - val_loss: 0.0899\n",
            "Epoch 78/100\n",
            "5354/5354 - 0s - loss: 0.0927 - val_loss: 0.0897\n",
            "Epoch 79/100\n",
            "5354/5354 - 0s - loss: 0.0926 - val_loss: 0.0896\n",
            "Epoch 80/100\n",
            "5354/5354 - 0s - loss: 0.0925 - val_loss: 0.0895\n",
            "Epoch 81/100\n",
            "5354/5354 - 0s - loss: 0.0924 - val_loss: 0.0894\n",
            "Epoch 82/100\n",
            "5354/5354 - 0s - loss: 0.0923 - val_loss: 0.0893\n",
            "Epoch 83/100\n",
            "5354/5354 - 0s - loss: 0.0922 - val_loss: 0.0892\n",
            "Epoch 84/100\n",
            "5354/5354 - 0s - loss: 0.0921 - val_loss: 0.0891\n",
            "Epoch 85/100\n",
            "5354/5354 - 0s - loss: 0.0920 - val_loss: 0.0890\n",
            "Epoch 86/100\n",
            "5354/5354 - 0s - loss: 0.0919 - val_loss: 0.0889\n",
            "Epoch 87/100\n",
            "5354/5354 - 0s - loss: 0.0918 - val_loss: 0.0888\n",
            "Epoch 88/100\n",
            "5354/5354 - 0s - loss: 0.0917 - val_loss: 0.0887\n",
            "Epoch 89/100\n",
            "5354/5354 - 0s - loss: 0.0916 - val_loss: 0.0886\n",
            "Epoch 90/100\n",
            "5354/5354 - 0s - loss: 0.0915 - val_loss: 0.0885\n",
            "Epoch 91/100\n",
            "5354/5354 - 0s - loss: 0.0914 - val_loss: 0.0885\n",
            "Epoch 92/100\n",
            "5354/5354 - 0s - loss: 0.0913 - val_loss: 0.0884\n",
            "Epoch 93/100\n",
            "5354/5354 - 0s - loss: 0.0913 - val_loss: 0.0883\n",
            "Epoch 94/100\n",
            "5354/5354 - 0s - loss: 0.0912 - val_loss: 0.0882\n",
            "Epoch 95/100\n",
            "5354/5354 - 0s - loss: 0.0911 - val_loss: 0.0882\n",
            "Epoch 96/100\n",
            "5354/5354 - 0s - loss: 0.0910 - val_loss: 0.0881\n",
            "Epoch 97/100\n",
            "5354/5354 - 0s - loss: 0.0910 - val_loss: 0.0880\n",
            "Epoch 98/100\n",
            "5354/5354 - 0s - loss: 0.0909 - val_loss: 0.0880\n",
            "Epoch 99/100\n",
            "5354/5354 - 0s - loss: 0.0908 - val_loss: 0.0879\n",
            "Epoch 100/100\n",
            "5354/5354 - 0s - loss: 0.0908 - val_loss: 0.0878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ff8f2f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5TsO_dVQIpl",
        "colab_type": "code",
        "outputId": "de8583cd-a36a-4f28-8246-2a63f6e68826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model_2.evaluate(train_anomaly_images, train_anomaly_images, batch_size=1024, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54051/1 - 0s - loss: 0.1150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11046588828595295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9eELDbRQLfF",
        "colab_type": "code",
        "outputId": "60ae4154-f2c0-437f-8c08-9ee73632cf95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model_encoder = Model(inputs=model_2.input, outputs=model_2.get_layer('memory_unit_4').output)\n",
        "\n",
        "model_encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "memory_unit_4 (MemoryUnit)   (None, 64)                6400      \n",
            "=================================================================\n",
            "Total params: 223,808\n",
            "Trainable params: 223,808\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIPdoiplzR5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MLRjql1PeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}